{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "To serve this slide deck, run the following line in the terminal or PowerShell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "jupyter nbconvert 'slides/advanced-web-scraping.ipynb' --to slides --output='../advanced-web-scraping'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advanced Web Scraping with Python\n",
    "\n",
    "<br>\n",
    "\n",
    "### Lorae Stojanovic\n",
    "\n",
    "<br>\n",
    "\n",
    "Welcome! We will start shortly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Agenda\n",
    "1. [Review: Web Scraping Basics](#/2)\n",
    "2. Selenium\n",
    "3. API Scraping\n",
    "4. Automating a web scrape with GitHub Actions\n",
    "4. Demo\n",
    "5. [Additional Resources](#/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Review: Web Scraping Basics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Web scraping**: The act of systematically extracting data from an online resource, such as a website.\n",
    "**Web crawling**: (use the explanation given by District Data Lab on /brookings repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How does a website work?\n",
    "### Your Web Browser\n",
    "Your web browser - like Chrome, Safari, Edge, or Firefox - is specialized software designed to display HTML files. \n",
    "\n",
    "### HTML and CSS\n",
    "HTML (HyperText Markup Language) and CSS (Cascading Style Sheets) are the languages of websites. HTML outlines the structure of the webpage, defining elements like text, images, and links. CSS styles the webpage, specifying colors, fonts, layout, and overall visual appearance.\n",
    "\n",
    "### Network Requests\n",
    "When you enter a URL (e.g., www.example.com) into your browser, several things happen:\n",
    "\n",
    "1. **DNS Lookup**:\n",
    "   - Your browser first translates the human-readable URL into an IP address using a Domain Name System (DNS) lookup. This IP address points to the server where the website is hosted.\n",
    "\n",
    "2. **HTTP Request**:\n",
    "   - The browser sends an HTTP (HyperText Transfer Protocol) request to the server at this IP address. This request asks for the main HTML file of the website.\n",
    "\n",
    "3. **Server Response**:\n",
    "   - The server processes this request and sends back the requested HTML file. This file contains the basic structure of the webpage.\n",
    "\n",
    "4. **Rendering HTML**:\n",
    "   - Your browser starts rendering the HTML file, which often includes references to other resources like CSS files, JavaScript files, images, fonts, and videos.\n",
    "\n",
    "5. **Additional Requests**:\n",
    "   - For each of these additional resources, the browser makes more HTTP requests to the server. For example:\n",
    "     - **CSS Files**: To style the webpage.\n",
    "     - **JavaScript Files**: To add interactivity and dynamic content.\n",
    "     - **Images and Videos**: To include multimedia content.\n",
    "     - **APIs**: Sometimes, the HTML or JavaScript code includes API requests. APIs (Application Programming Interfaces) allow the browser to request and receive data from servers, often in JSON format, which can then be dynamically displayed on the webpage.\n",
    "\n",
    "6. **Assembling the Page**:\n",
    "   - The browser assembles all these elements and displays the fully rendered webpage to you.\n",
    "\n",
    "TODOL: explain what a server is\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2. Selenium\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 5. Additional Resources\n",
    "Links to resources (both internal Brookings resources and publicly available ones) that will provide additional context/training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Note to self: Make the slides some sort of table that easily indicate which resources are internal and which aren't"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## If you want a light introduction to web scraping\n",
    "[DistrictDataLabs/brookings](https://github.com/DistrictDataLabs/brookings/) **Publicly available** GitHub repository presented to Brookings Data Network on March 31, 2017 which has slides and sample code. The resource is older, but the concepts are still relevant. [NOTE: I haven't tested the code, so I'm not sure if it still works]\n",
    "\n",
    "Keywords: Publicly available datasets, common data formats, RESTful APIs, HTTP requests, web scraping vs web crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you want a more involved introduction to web scraping\n",
    "[trainingNotebook.ipynb](https://brookingsinstitution.sharepoint.com/:f:/r/sites/BrookingsDataNetwork/Shared%20Documents/Python/2017-05%20-%20Getting%20Started%20with%20Web%20Scraping?csf=1&web=1&e=d2sfux) Curtlyn Kramer's **Brookings internal** Jupyter notebook, presented to the Brookings Data Network on May 26, 2017. This is only useful if the code works, so I will have to test if the code works. If it does, then this is a helpful Jupyter notebook that walks you through the steps.\n",
    "\n",
    "Keywords: inspect element, BeautifulSoup4, "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
